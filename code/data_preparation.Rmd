---
title: "Data preparation"
author: "Antton Alberdi/Raphael Eisenhofer"
date: "18/7/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
The data preparation script cleans the raw datasets for smooth downstream analyses. Original CSV files were downloaded from the EHI Airtable database on the 1st of July 2023, and stored in the data directory of this repository.

### Data source
```{r batch, echo=FALSE}
batch="2023_07_01"
wd=getwd()
```

## Load libraries
```{r libraries, include=FALSE}
library(tidyverse)
```

# Clean data files

## Field and laboratory work
Cleaning tables related to field and laboratory work

### Samples
```{r samples_prep, echo=FALSE}
hi<-read.csv(paste0(wd,"/../data/original/",batch,"/samples_",batch,".csv")) %>%
  #select relevant columns
  select(
    #Sample columns
    Code,Type,Freshness,Freezing,
    #Host specimen columns
    Specimen.ID,Species,Order,Family,Class..from.Specimen.ID...from.Captures.ID.,Development,Sex,Length..mm.,Weight..g.,
    #Capture columns
    Captures.ID,Sampling_events,Place,Country,Biome,Environment,Latitude.reduced,Longitude.reduced) %>%
  #rename columns
  rename(
    #Sample columns
    sample_id=Code,
    sample_type=Type,
    sample_freshness=Freshness,
    sample_freezing=Freezing,
    #Host specimen columns
    specimen_id=Specimen.ID,
    specimen_species=Species,
    specimen_order=Order,
    specimen_family=Family,
    specimen_class=Class..from.Specimen.ID...from.Captures.ID.,
    specimen_development=Development,
    specimen_sex=Sex,
    specimen_length=Length..mm.,
    specimen_weight=Weight..g.,
    #Capture columns
    capture_id=Captures.ID,
    capture_event_id=Sampling_events,
    capture_place=Place,
    capture_country=Country,
    capture_biome=Biome,
    capture_environment=Environment,
    capture_latitude=Latitude.reduced,
    capture_longitude=Longitude.reduced,
  ) %>%
  #remove negative controls
  filter(specimen_id != "") %>%
  #save clean table
  write.csv(paste0(wd,"/../data/samples.csv"), row.names = FALSE)
```

### Extraction
```{r extraction_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/extraction_",batch,".csv")) %>%
  #select relevant columns
  select(
    Ex.code,EX.batch,EX.ng.ul,EX.ul,EX.DNA.ng,BB.sample
  ) %>%
  #rename columns
  rename(
    extraction_id=Ex.code,
    extraction_batch=EX.batch,
    extraction_concentration=EX.ng.ul,
    extraction_volume=EX.ul,
    extraction_total=EX.DNA.ng,
    sample_id=BB.sample,
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/extraction.csv"), row.names = FALSE)
```

### Library
```{r library_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/library_",batch,".csv")) %>%
  #select relevant columns
  select(
    #sample identifiers
    LI.Code,LI.Batch,Sample,EX.Sample,Sequencing.datasets,
    #library stats
    Input.volume,Input.DNA..ng.,EX.concentration..ng.ul.,Adaptor.nM,Required.PCR.cycles
  ) %>%
  #rename columns
  rename(
    #sample identifiers
    library_id=LI.Code,
    library_batch=LI.Batch,
    sample_id=Sample,
    extraction_id=EX.Sample,
    sequencing_datasets=Sequencing.datasets,
    #library stats
    library_input_volume=Input.volume,
    library_input_dna=Input.DNA..ng.,
    library_input_dna_concentration=EX.concentration..ng.ul.,
    library_adaptor_molarity=Adaptor.nM,
    library_PCR_cycles=Required.PCR.cycles
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/library.csv"), row.names = FALSE)
```

### Index
```{r index_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/index_",batch,".csv")) %>%
  #select relevant columns
  select(
    #sample identifiers
    IN.Code,IN.batch,LI.Sample,EX.Code,sample,
    #library stats
    Initial.DNA.for.library,Number.of.PCR.cycles,
    #indexing stats
    Adaptors..nM.,Library..nM.,Volume.ul,DNA.mols
  ) %>%
  #rename columns
  rename(
    #sample identifiers
    index_id=IN.Code,
    index_batch=IN.batch,
    library_id=LI.Sample,
    extraction_id=EX.Code,
    sample_id=sample,
    #library stats
    library_input_dna=Initial.DNA.for.library,
    library_PCR_cycles=Number.of.PCR.cycles,
    #indexing stats
    index_adaptors_molarity=Adaptors..nM.,
    index_library_molarity=Library..nM.,
    index_volume=Volume.ul,
    index_library_moles=DNA.mols
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/index.csv"), row.names = FALSE)
```

### Sequence
```{r sequence_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/sequence_",batch,".csv")) %>%
  #select relevant columns
  select(
    #sample identifiers
    EHI_number,SE.Batch,IN.Code,
    #pooling information
    Molarity..library.,Index,Dilution.1.n,Volume..ul.,Moles,Adaptor.library.ratio,
    #sequencing information
    Raw.data.size..GB.,Q20.,Q30.,GC.
  ) %>%
  #rename columns
  rename(
    #sample identifiers
    sequence_id=EHI_number,
    sequence_batch=SE.Batch,
    index_id=IN.Code,
    #pooling information
    index_library_molarity=Molarity..library.,
    pooling_index=Index,
    pooling_dilution=Dilution.1.n,
    pooling_volume=Volume..ul.,
    pooling_moles=Moles,
    pooling_adator_library_ratio=Adaptor.library.ratio,
    #sequencing information
    sequence_data=Raw.data.size..GB.,
    sequence_q20=Q20.,
    sequence_q30=Q30.,
    sequence_gc=GC.
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/sequence.csv"), row.names = FALSE)
```

## Bioinformatics
Cleaning tables related to bioinformatic processing of the data.

### Preprocessing
```{r preprocessing_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/preprocessing_",batch,".csv")) %>%
  #select relevant columns
  select(
    #data identifiers
    Code,PR_Batch,EHI_number,IN.Code..from.EHI_number.,
    #host genome info
    Reference.genome.species,Reference.genome.closeness,
    #quality-filtering stats
    reads_pre_fastp,reads_post_fastp,bases_pre_fastp,bases_post_fastp,adapter_trimmed_reads,adapter_trimmed_bases,host_reads,metagenomic_bases,host_bases,
    #prokarotic fraction estimation
    bacterial_archaeal_bases,singlem_fraction,
    #metagenomic complexity estimation
    C
  ) %>%
  #rename columns
  rename(
    #data identifiers
    preprocessing_id=Code,
    preprocessing_batch=PR_Batch,
    sequence_id=EHI_number,
    index_id=IN.Code..from.EHI_number.,
    #host genome info
    reference_species=Reference.genome.species,
    reference_closenees=Reference.genome.closeness,
    #metagenomic complexity estimation
    nonpareil_coverage=C
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/preprocessing.csv"), row.names = FALSE)
```

### Assembly
```{r assembly_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/assembly_",batch,".csv")) %>%
  #select relevant columns
  select(
    #data identifiers
    ID,Assembly_code,AB_batch,PreprocessedSample,EHI_number,
    #assembly information
    Type..from.AB.Batch.,metagenomic_bases,
    #stats
    assembly_length,N50,L50,num_contigs,largest_contig,num_bins,assembly_mapping_percent
  ) %>%
  #rename columns
  rename(
    #data identifiers
    assembly_input_id=ID, #in coassemblies multiple assembly_input_id's link to a single assembly_id
    assembly_id=Assembly_code,
    assembly_batch=AB_batch,
    preprocessing_id=PreprocessedSample,
    sequence_id=EHI_number,
    #assembly information
    assembly_type=Type..from.AB.Batch.,
    assembly_input_bases=metagenomic_bases,
    #stats
    assembly_n50=N50,
    assembly_l50=L50,
    assembly_num_contigs=num_contigs,
    assembly_largest_contig=largest_contig,
    assembly_num_bins=num_bins
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/assembly.csv"), row.names = FALSE)
```

### MAGs
```{r mags_prep, echo=FALSE}
read.csv(paste0(wd,"/../data/original/",batch,"/mags_",batch,".csv")) %>%
  #select relevant columns
  select(
    #data identifiers
    ID,mag_name,link_to_assembly,AB_batch,
    #taxonomy
    domain,phylum,class,order,family,genus,species,closest_placement_ani,closest_placement_af,taxonomy_level,
    #mag stats
    completeness,contamination,size,GC,N50,contigs,
    #host
    host_species
  ) %>%
  #rename columns
  rename(
    #data identifiers
    mag_id=ID,
    mag_name=mag_name,
    assembly_id=link_to_assembly,
    assembly_batch=AB_batch,
    #taxonomy
    mag_domain=domain,
    mag_phylum=phylum,
    mag_class=class,
    mag_order=order,
    mag_family=family,
    mag_genus=genus,
    mag_species=species,
    mag_closest_ani=closest_placement_ani,
    mag_closest_af=closest_placement_af,
    mag_taxonomy=taxonomy_level,
    #mag stats
    mag_completeness=completeness,
    mag_contamination=contamination,
    mag_size=size,
    mag_gc=GC,
    mag_n50=N50,
    mag_contigs=contigs
  ) %>%
  #save clean table
  write.csv(paste0(wd,"/../data/mags.csv"), row.names = FALSE)
```

### Merge tables
```{r, echo=FALSE, message=FALSE}
#Raphael
library(tidyverse)
library(janitor)

ppr <- read_delim("../data/preprocessing.csv")
sam <- read_delim("../data/samples.csv") %>%
  #remove duplicate sample_id value
  filter(specimen_id != "SD00419")
ext <- read_delim("../data/extraction.csv") %>%
  select(!sample_id)
lib <- read_delim("../data/library.csv") %>%
  filter(., !is.na(sequencing_datasets))
seq <- read_delim("../data/sequence.csv") %>%
  mutate(library_id = str_replace_all(index_id, "..$", "")) %>%
  select(!index_id)
dups <- read_delim("../data/host_duplicates.tsv", col_names = c("ehi", "host_dup_percent"))

combined <- ppr %>%
  inner_join(., seq, by = "sequence_id", keep = FALSE) %>%
  inner_join(., lib, by = "library_id", keep = FALSE) %>%
  inner_join(., ext, by = "extraction_id", keep = FALSE) %>%
  inner_join(., sam, by = "sample_id") %>%
  inner_join(., dups, by = c("sequence_id" = "ehi")) %>%
  # Create categories based on host taxonomy
  mutate(singlem_fraction = as.numeric(str_replace(singlem_fraction, "%", ""))/100,
         host_percent = host_bases / bases_post_fastp,
         tax_group = case_when(
    str_detect(specimen_order, "Rodentia") ~ "Rodents",
    str_detect(specimen_order, "Chiroptera") ~ "Bats",
    str_detect(specimen_order, "Squamata") ~ "Reptiles",
    str_detect(specimen_class, "Aves") ~ "Birds",
    str_detect(specimen_order, "Urodela") ~ "Amphibians"
  )) %>%

  write_delim(paste0(wd, "/../data/combined.tsv"))
```

